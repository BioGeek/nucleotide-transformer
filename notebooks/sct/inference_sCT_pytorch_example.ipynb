{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference with sCellTransformer - PyTorch version from HuggingFace\n",
    "\n",
    "sCT was ported from `jax` to `PyTorch`, and then released through HuggingFace.  \n",
    "This notebook aims to ensure that the HuggingFace model works properly, by loading it and using it on dummy sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open All Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/instadeepai/nucleotide-transformer/blob/main/notebooks/sct/inference_sCT_pytorch_example.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T07:50:47.544612Z",
     "start_time": "2025-06-06T07:50:47.538478Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    import nucleotide_transformer\n",
    "except:\n",
    "    !pip install git+https://github.com/instadeepai/nucleotide-transformer@main |tail -n 1\n",
    "    !pip install anndata\n",
    "    !pip install scanpy\n",
    "    !pip install cellxgene_census\n",
    "    !pip install transformers\n",
    "    !pip install einops\n",
    "    !pip install torch\n",
    "    import nucleotide_transformer\n",
    "\n",
    "if \"COLAB_TPU_ADDR\" in os.environ:\n",
    "    from jax.tools import colab_tpu\n",
    "\n",
    "    colab_tpu.setup_tpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T07:50:52.872346Z",
     "start_time": "2025-06-06T07:50:48.163017Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "import os\n",
    "import json\n",
    "import anndata as ad\n",
    "import cellxgene_census\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import math\n",
    "import itertools\n",
    "from scipy.sparse import issparse\n",
    "from typing import Any\n",
    "\n",
    "from nucleotide_transformer.sCellTransformer.model import sCT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T07:50:57.729403Z",
     "start_time": "2025-06-06T07:50:54.022075Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loading the model from HuggingFace\n",
    "model = AutoModel.from_pretrained(\"InstaDeepAI/sCellTransformer\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T07:56:21.091995Z",
     "start_time": "2025-06-06T07:55:07.965186Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 42.8M/42.8M [00:58<00:00, 769kB/s]\n"
     ]
    }
   ],
   "source": [
    "# Downloading the file from the public API of cellxgene\n",
    "# This file is a h5ad file containing single-cell RNA-seq data\n",
    "# It corresponds to Sst Chodl - MTG: Seattle Alzheimer's Disease Atlas (SEA-AD)\n",
    "# - Single-cell RNA-seq data: cells x genes expression matrix\n",
    "# - Sparse data (~90% zeros), typically 16k cells, ~30k genes\n",
    "# - Contains cell type annotations (neurons, astrocytes, etc.) and metadata\n",
    "# - Real biological data vs synthetic test data - will need preprocessing for model\n",
    "# Open the Census (using the same version as your S3 path: 2023-12-15)\n",
    "cellxgene_census.download_source_h5ad(\n",
    "    \"81e91ff8-f619-4ad1-a0c3-b45e1dc63f68\",\n",
    "    to_path=\"brain.h5ad\",\n",
    "    census_version=\"2023-12-15\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T07:56:41.705799Z",
     "start_time": "2025-06-06T07:56:41.675371Z"
    }
   },
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "\n",
    "# Loading mapping from ENSEMBL name to index in the dataset.\n",
    "with open(os.path.join(current_dir, \"data/ensembl_id_vocab.json\"), \"r\") as f:\n",
    "    ENSEMBL_ID_VOCAB = json.load(f)\n",
    "\n",
    "# Loading mapping, for the considered coding genes,\n",
    "# between global index in the dataset and their index among coding genes only.\n",
    "# Restricting from 60k genes to 20k genes only. \n",
    "with open(os.path.join(current_dir, \"data/protein_gene_map.json\"), \"r\") as f:\n",
    "    PROTEIN_GENE_MAP = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define dataloader functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T07:56:43.618235Z",
     "start_time": "2025-06-06T07:56:42.825087Z"
    }
   },
   "outputs": [],
   "source": [
    "def define_mapping_between_adata_and_model(adata: ad.AnnData,\n",
    "                                           ENSEMBL_ID_VOCAB: dict,\n",
    "                                           PROTEIN_GENE_MAP: dict) -> np.ndarray:\n",
    "    # Define mapping\n",
    "    names = list(adata.var.feature_name.keys())\n",
    "    MAP_TO_PROTEIN_GENE_INDEX = {}\n",
    "    indexes_present_in_data = {}\n",
    "    for i, name in enumerate(names):\n",
    "        if name in ENSEMBL_ID_VOCAB:\n",
    "            index = str(ENSEMBL_ID_VOCAB[name])\n",
    "            if index in PROTEIN_GENE_MAP:\n",
    "                indexes_present_in_data[index] = 1\n",
    "                MAP_TO_PROTEIN_GENE_INDEX[str(i)] = PROTEIN_GENE_MAP[index]\n",
    "\n",
    "    # Create gene mapping arrays\n",
    "    gene_map = {int(k): MAP_TO_PROTEIN_GENE_INDEX[k] for k in MAP_TO_PROTEIN_GENE_INDEX}\n",
    "    new_gene_map_array = np.full(70000, -1, dtype=np.int32)\n",
    "    for k, v in gene_map.items():\n",
    "        new_gene_map_array[k] = v\n",
    "    return new_gene_map_array\n",
    "\n",
    "\n",
    "# Note that this data download already includes a log normalization \n",
    "# on the gene expression levels.\n",
    "adata = sc.read_h5ad('brain.h5ad')\n",
    "# Creating the mapping between indexes in the downloaded dataset and \n",
    "# the index in the model for the considered coding genes. \n",
    "new_gene_map_array = define_mapping_between_adata_and_model(\n",
    "    adata=adata,\n",
    "    ENSEMBL_ID_VOCAB=ENSEMBL_ID_VOCAB,\n",
    "    PROTEIN_GENE_MAP=PROTEIN_GENE_MAP\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How is the data formatted?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is formatted as a h5ad file.\n",
    "It contains:\n",
    "- data.X: It is a sparse matrix of gene expression levels (shape: num_cells x num_genes). \n",
    "- data.var[\"feature_name\"]: contains the name of the genes (shape: num_genes)\n",
    "- the data also contains many metadata columns such as the cell type, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T07:56:55.726734Z",
     "start_time": "2025-06-06T07:56:55.709237Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_h5ad_scrna_dataset(\n",
    "        adata: Any,\n",
    "        new_gene_map_array: np.ndarray,\n",
    "        num_downsamples: int,\n",
    "        cell_len: int,\n",
    "        num_cells: int,\n",
    "        pad_token_id: int,\n",
    "        gene_expression_num_bins: int,\n",
    "        batch_size: int,\n",
    ") -> Any:\n",
    "    \"\"\"\n",
    "    Creates an iterable dataset from h5ad file for single-cell RNA-seq data.\n",
    "    \n",
    "    Args:\n",
    "        h5ad_path: Path to the h5ad file\n",
    "        new_gene_map_array: Array mapping new gene indices to your previous index system\n",
    "        num_downsamples: Number of downsampling steps\n",
    "        cell_len: Length of each cell in the dataset\n",
    "        num_cells: Number of cells per sample\n",
    "        pad_token_id: Token ID for padding\n",
    "        gene_expression_num_bins: Number of bins for gene expression\n",
    "        batch_size: Batch size\n",
    "    \n",
    "    Returns:\n",
    "        An iterable dataset that yields batches of samples\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract expression matrix (usually X is sparse)\n",
    "    expr_matrix = adata.X\n",
    "    if issparse(expr_matrix):\n",
    "        # Convert to CSR for efficient row access\n",
    "        expr_matrix = expr_matrix.tocsr()\n",
    "\n",
    "    # Calculate sequence length with downsampling\n",
    "    downsample_factor = 2 ** num_downsamples\n",
    "    seq_length = math.ceil(cell_len / downsample_factor) * downsample_factor\n",
    "\n",
    "    class H5adIterableDataset:\n",
    "        def __init__(self):\n",
    "            self.length = cell_len\n",
    "            self.batch_size = batch_size\n",
    "            self.total_cells = expr_matrix.shape[0]\n",
    "\n",
    "        def __len__(self):\n",
    "            return self.length\n",
    "\n",
    "        def __iter__(self):\n",
    "            # Create infinite iterator over cell indices\n",
    "            cell_indices = itertools.cycle(range(self.total_cells))\n",
    "\n",
    "            while True:\n",
    "                batch = []\n",
    "\n",
    "                # Generate batch_size samples\n",
    "                for _ in range(self.batch_size):\n",
    "                    cells = []\n",
    "\n",
    "                    # Collect num_cells cells for one sample\n",
    "                    while len(cells) < num_cells:\n",
    "                        cell_idx = next(cell_indices)\n",
    "\n",
    "                        # Get expression data for this cell\n",
    "                        if issparse(expr_matrix):\n",
    "                            # For sparse matrix, get the row as a dense array\n",
    "                            cell_expr = expr_matrix[cell_idx, :].toarray().flatten()\n",
    "                        else:\n",
    "                            cell_expr = expr_matrix[cell_idx, :]\n",
    "\n",
    "                        # Find non-zero expressions\n",
    "                        non_zero_mask = cell_expr > 0\n",
    "                        gene_idxs = np.where(non_zero_mask)[0].astype(np.int32)\n",
    "                        expressions = cell_expr[non_zero_mask].astype(np.float32)\n",
    "\n",
    "                        if len(gene_idxs) == 0:\n",
    "                            # Skip cells with no expression\n",
    "                            continue\n",
    "\n",
    "                        # Map genes using new_gene_map_array\n",
    "                        mapped_idxs = new_gene_map_array[gene_idxs]\n",
    "                        valid_mask = mapped_idxs != -1\n",
    "                        positions = mapped_idxs[valid_mask]\n",
    "                        valid_expr = expressions[valid_mask]\n",
    "\n",
    "                        if len(valid_expr) == 0:\n",
    "                            continue\n",
    "\n",
    "                        # Bin expressions\n",
    "                        if min(valid_expr) == max(valid_expr):\n",
    "                            bin_edges = np.array(\n",
    "                                [min(valid_expr) - 0.1, max(valid_expr) + 0.1])\n",
    "                            binned = np.ones_like(valid_expr, dtype=np.int32)\n",
    "                        else:\n",
    "                            bin_edges = np.linspace(\n",
    "                                min(valid_expr),\n",
    "                                max(valid_expr),\n",
    "                                gene_expression_num_bins,\n",
    "                            )\n",
    "                            bin_edges[-1] += 0.01\n",
    "                            binned = np.digitize(valid_expr, bin_edges)\n",
    "\n",
    "                        # Create full arrays (using the original gene_ids from your code)\n",
    "                        full_expr = np.zeros(self.length, dtype=np.int32)\n",
    "                        full_expr[positions] = binned\n",
    "\n",
    "                        raw_expr = np.zeros(self.length, dtype=np.float32)\n",
    "                        raw_expr[positions] = valid_expr\n",
    "\n",
    "                        # Create cell dictionary\n",
    "                        cell = {\n",
    "                            # \"gene_ids\": gene_ids.copy(),\n",
    "                            \"gene_expressions\": full_expr,\n",
    "                            \"raw_gene_expressions\": raw_expr,\n",
    "                            \"bins\": bin_edges,\n",
    "                            \"source\": [\"h5ad\"],\n",
    "                        }\n",
    "\n",
    "                        # Pad if needed\n",
    "                        if seq_length > self.length:\n",
    "                            for key in [\"gene_expressions\",\n",
    "                                        \"raw_gene_expressions\"]:\n",
    "                                pad_value = pad_token_id\n",
    "                                padded = np.full(seq_length, pad_value,\n",
    "                                                 dtype=cell[key].dtype)\n",
    "                                padded[:len(cell[key])] = cell[key]\n",
    "                                cell[key] = padded\n",
    "\n",
    "                        cells.append(cell)\n",
    "\n",
    "                    # Merge cells for this sample\n",
    "                    if len(cells) == num_cells:\n",
    "                        sample = {}\n",
    "\n",
    "                        # Merge arrays by concatenation\n",
    "                        for key in cells[0]:\n",
    "                            if isinstance(cells[0][key], np.ndarray):\n",
    "                                sample[key] = np.concatenate([c[key] for c in cells])\n",
    "                            else:\n",
    "                                sample[key] = list(itertools.chain.from_iterable(\n",
    "                                    c[key] for c in cells\n",
    "                                ))\n",
    "\n",
    "                        batch.append(sample)\n",
    "\n",
    "                # Reshape and yield batch\n",
    "                if len(batch) == self.batch_size:\n",
    "                    batch_result = {}\n",
    "\n",
    "                    for key in batch[0]:\n",
    "                        if isinstance(batch[0][key], np.ndarray):\n",
    "                            batch_arrays = [b[key] for b in batch]\n",
    "                            batch_result[key] = np.stack(batch_arrays, axis=0)\n",
    "                        else:\n",
    "                            batch_result[key] = [b[key] for b in batch]\n",
    "\n",
    "                    yield batch_result\n",
    "\n",
    "    return H5adIterableDataset()\n",
    "\n",
    "\n",
    "# Create dataset\n",
    "dataloader = get_h5ad_scrna_dataset(\n",
    "    adata=adata,\n",
    "    new_gene_map_array=new_gene_map_array,\n",
    "    num_downsamples=model.config.num_downsamples,\n",
    "    cell_len=len(PROTEIN_GENE_MAP),\n",
    "    num_cells=model.config.num_cells,\n",
    "    pad_token_id=model.config.pad_token_id,\n",
    "    gene_expression_num_bins=5,\n",
    "    batch_size=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T08:03:05.769124Z",
     "start_time": "2025-06-06T08:03:05.757741Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_gene_expression_imputation(\n",
    "        model: sCT,\n",
    "        train_dataloader: DataLoader,\n",
    "        num_batches: int|None = 10,\n",
    "        mask_ratio: float = 0.15,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Evaluate a gene expression imputation model using Matthews Correlation Coefficient.\n",
    "\n",
    "    Args:\n",
    "        model: PyTorch model for gene expression imputation\n",
    "        train_dataloader: DataLoader containing gene expression data\n",
    "        num_batches: Number of batches to evaluate. If None, all batches are evaluated\n",
    "        mask_ratio: Ratio of tokens to mask for imputation\n",
    "\n",
    "    Returns:\n",
    "        float: Average Matthews Correlation Coefficient across all batches\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    # Lists to store true and predicted values for masked tokens\n",
    "    all_true_values = []\n",
    "    all_pred_values = []\n",
    "\n",
    "    # Iterate over specified number of batches\n",
    "    iterator = iter(train_dataloader)\n",
    "    \n",
    "    if num_batches is None:\n",
    "        num_batches = len(train_dataloader)\n",
    "\n",
    "    for batch_idx in tqdm(range(num_batches)):\n",
    "        try:\n",
    "            # Get next batch\n",
    "            batch = next(iterator)\n",
    "\n",
    "            # Move batch to the same device as model\n",
    "            device = next(model.parameters()).device\n",
    "            gene_expressions = torch.tensor(batch[\"gene_expressions\"], device=device)\n",
    "\n",
    "            # Create random mask\n",
    "            mask = torch.rand(gene_expressions.shape, device=device) < mask_ratio\n",
    "\n",
    "            # Clone and mask gene expressions\n",
    "            masked_gene_expressions = gene_expressions.clone()\n",
    "            masked_gene_expressions[mask] = model.config.mask_token_id\n",
    "\n",
    "            # Keep original values before masking for evaluation\n",
    "            true_values = gene_expressions[mask].detach().cpu().numpy()\n",
    "\n",
    "            # Forward pass without gradient computation\n",
    "            with torch.no_grad():\n",
    "                outputs = model(masked_gene_expressions)\n",
    "\n",
    "            # Extract logits from model output (adapt based on your model's output format)\n",
    "            if isinstance(outputs, dict):\n",
    "                logits = outputs.get(\"logits\", outputs)\n",
    "            else:\n",
    "                logits = outputs\n",
    "\n",
    "            # Get predictions (assuming classification - adjust if regression)\n",
    "            predictions = torch.argmax(logits[:,:,:5], dim=-1)\n",
    "            pred_values = predictions[mask].detach().cpu().numpy()\n",
    "\n",
    "            # Store true and predicted values\n",
    "            all_true_values.append(true_values)\n",
    "            all_pred_values.append(pred_values)\n",
    "\n",
    "        except StopIteration:\n",
    "            print(f\"DataLoader exhausted after {batch_idx} batches\")\n",
    "            break\n",
    "\n",
    "    # Concatenate all batches\n",
    "    all_true_values = np.concatenate(all_true_values)\n",
    "    all_pred_values = np.concatenate(all_pred_values)\n",
    "\n",
    "    # Compute Matthews Correlation Coefficient\n",
    "    # - Binary classification metric ranging from -1 to +1\n",
    "    # - +1: perfect prediction, 0: random prediction, -1: total disagreement\n",
    "    # - Balanced metric that works well with imbalanced datasets\n",
    "    # - Considers all confusion matrix elements (TP, TN, FP, FN)\n",
    "    mcc = matthews_corrcoef(all_true_values, all_pred_values)\n",
    "    print(f\"Overall MCC: {mcc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T08:03:57.556352Z",
     "start_time": "2025-06-06T08:03:06.547889Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:50<00:00, 50.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 998400, 7])\n",
      "Overall MCC: 0.3663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "# Define the number of batches and the mask ratio for evaluation\n",
    "# The reported metric is the average MCC across all batches computed over the bins.\n",
    "evaluate_gene_expression_imputation(\n",
    "    model,  \n",
    "    dataloader,\n",
    "    num_batches=1,\n",
    "    mask_ratio=0.15,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genomics-research-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
